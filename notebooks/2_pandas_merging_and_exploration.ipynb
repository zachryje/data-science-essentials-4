{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0abe137f",
   "metadata": {},
   "source": [
    "In this notebooks, we'll learn first how to combine multiple DataFrame using the `merge` method and then see how we can further explore the resulting DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86c1357",
   "metadata": {},
   "source": [
    "## Merging _pandas_ DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e57ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8825ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment = pd.read_csv('../data/tn_unemployment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fe5c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc189f0a",
   "metadata": {},
   "source": [
    "This unemployment data was obtained from the Burea of Labor Statistics.\n",
    "\n",
    "Notice that it includes the labor force for each county in the LF column along with the number employed and number unemployed.\n",
    "\n",
    "We can easily verify the unemployment rate values by dividing the Unemployed column by the LF column. Using `pandas`, we can do these types of operations on whole columns at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff272764",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment['Unemployed'] / unemployment['LF']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc5c407",
   "metadata": {},
   "source": [
    "We can also multiply an entire column by a number. For example, if we can to convert the proportions from above to percentages, we can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4656fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "100 * unemployment['Unemployed'] / unemployment['LF']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6341d75c",
   "metadata": {},
   "source": [
    "Now, let's bring in our second DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d4bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv('../data/tn_population.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c1bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "population.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c17e64",
   "metadata": {},
   "source": [
    "Our goal is to combine the unemployment and population data. In order to do this, _pandas_ needs a common column to join on. \n",
    "\n",
    "Notice that the `Name` column from `unemployment` and the `County Name` column from `population` almost work, except that `Name` also includes \", TN\". Let's remove this part so that we have a column to join on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6be226",
   "metadata": {},
   "source": [
    "### Brief Detour - String Methods\n",
    "\n",
    "When working with text data in `pandas`, it is often useful to utilize the built-in sting methods. To use these methods, you must prepend a `.str` before the desired method.\n",
    "\n",
    "For example, we can make column entirely uppercase using the `upper()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e8203",
   "metadata": {},
   "outputs": [],
   "source": [
    "population['County Name'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee8ea48",
   "metadata": {},
   "source": [
    "Another often useful method is the `replace()` method. To use this method, specify what pattern you want to replace and then the replacement text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c2168",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment['Period'].str.replace('21', '2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25670c3a",
   "metadata": {},
   "source": [
    "A method that we can use that will allow us to merge our dataframes is the `.str.split()` method.\n",
    "\n",
    "Notice that if we split on the comma, the first piece will match what is contained in the `County Name` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d700d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment['Name'].str.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3bd918",
   "metadata": {},
   "source": [
    "By default, this method returns a list. We can make it return a DataFrame by using the `expand` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb56e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment['Name'].str.split(',', expand = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9498e3c",
   "metadata": {},
   "source": [
    "We only want the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eebe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment['Name'].str.split(',', expand = True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996be192",
   "metadata": {},
   "source": [
    "Finally, we can assign this back to the `Name` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde09c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment['Name'] = unemployment['Name'].str.split(',', expand = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c76978",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23739a89",
   "metadata": {},
   "source": [
    "Now, we are ready to merge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a48f7c",
   "metadata": {},
   "source": [
    "**Option 1:** Use the `left_on` and `right_on` arguments to tell pandas what to merge on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3776746",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left = population, right = unemployment, left_on = 'County Name', right_on = 'Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1184d0a7",
   "metadata": {},
   "source": [
    "Notice that we end up with a duplicated column (with different names)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9155d2ab",
   "metadata": {},
   "source": [
    "**Option 2:** Rename the merging column for one of our DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e355767",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left = population,\n",
    "         right = unemployment.rename(columns = {'Name': 'County Name'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5ac17",
   "metadata": {},
   "source": [
    "We can even select out just the columns that we need after the merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb85180",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left = population,\n",
    "         right = unemployment[['Name', 'unemployment_rate']].rename(columns = {'Name': 'County Name'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7f56fb",
   "metadata": {},
   "source": [
    "Once we're happy with the results, we can save them to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b3f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_counties = pd.merge(left = population,\n",
    "         right = unemployment[['Name', 'unemployment_rate']].rename(columns = {'Name': 'County Name'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f492dc2",
   "metadata": {},
   "source": [
    "Now, let's add in some additional information about these counties - which Grand Division they belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f3557",
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_divisions = pd.read_csv('../data/tn_divisions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718604fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_divisions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74517e72",
   "metadata": {},
   "source": [
    "**Your Turn:** Merge tn_counties with grand_divisions. Save the results back to `tn_counties`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7536a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3834e52f",
   "metadata": {},
   "source": [
    "## Further Methods of Slicing and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9ea7af",
   "metadata": {},
   "source": [
    "When working with numeric data, it is often useful to look at some summary statistics. The `describe()` method is an easy way to get a summary of a numeric column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3caf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_counties['Population'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fa87e4",
   "metadata": {},
   "source": [
    "Let's now find all counties in East Tennessee that have at least 100,000 residents.\n",
    "\n",
    "We saw last week how we could use `.loc` to filter a DataFrame. If there are multiple conditions we want to filter on, we can still use `.loc`, but we must first surround each condition in parentheses and separate the conditions by an &."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a9261",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_counties.loc[(tn_counties['Division'] == 'East') & (tn_counties['Population'] >= 100000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba3b79d",
   "metadata": {},
   "source": [
    "The & means that pandas will find all rows that meet both conditions. You can think of & as \"and\". If we want to find all rows that meet either condition a _or_ condition b, we can use the |, which can be thought of as \"or\".\n",
    "\n",
    "For example, if we want to find any counties that have either at least 250,000 residents _or_ have unemployment less than 4%, we can accomplish this using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b0c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_counties.loc[(tn_counties['Population'] >= 250000) | (tn_counties['unemployment_rate'] < 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0b4a64",
   "metadata": {},
   "source": [
    "If we want to filter down to the rows matching 2 or more conditions, we can either string together a series of conditions with | or we can use the `.isin` method and provide a list of values we want to match.\n",
    "\n",
    "For example, if we want to look at the rows for Davidson, Shelby, Knox, and Hamilton Counties, we could accomplish it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_counties = ['Davidson County', 'Shelby County', 'Knox County', 'Hamilton County']\n",
    "\n",
    "tn_counties.loc[tn_counties['County Name'].isin(metro_counties)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bba19b8",
   "metadata": {},
   "source": [
    "Finally, if we want to negate a condition, we can do so using a ~.\n",
    "\n",
    "For example, let's say we want to find all counties besides the four metro counties above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ce6287",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_counties.loc[~tn_counties['County Name'].isin(metro_counties)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
